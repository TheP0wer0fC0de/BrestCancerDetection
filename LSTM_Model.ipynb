{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6qn30ED_TxN"
      },
      "source": [
        "***RNN Model - LSTM***\n",
        "\n",
        "Reference: OMKAR MODI https://www.kaggle.com/omkarmodi/inceptionv3-feature-extraction/notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onAowYj1CCYQ"
      },
      "source": [
        "#This Program imports a dataset obtained from Kaggle\n",
        "#https://www.kaggle.com/aryashah2k/breast-ultrasound-images-dataset\n",
        "#It then classifies the Ultrasound Images as benign, malignant, or normal\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing\n",
        "\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gc-LR6RQCIyW",
        "outputId": "fea2abd7-5e2c-4d56-bbe6-5aed1bbe1044"
      },
      "source": [
        "pip install openpyxl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.7/dist-packages (2.5.9)\n",
            "Requirement already satisfied: jdcal in /usr/local/lib/python3.7/dist-packages (from openpyxl) (1.4.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VUa5dwxCI09"
      },
      "source": [
        "from tensorflow import keras\n",
        "import cv2\n",
        "from tensorflow.keras.preprocessing.image import load_img ,img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D,AveragePooling2D,BatchNormalization\n",
        "from tensorflow.keras.layers import Dense,Activation\n",
        "from tensorflow.keras.layers import Flatten,Dropout,SpatialDropout2D,AveragePooling2D,GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aTur7OOCI3y",
        "outputId": "3c2400e2-9ca1-464d-bf17-70dc30d92398"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eghgbYA2CI6e",
        "outputId": "df042e54-8f45-47aa-f402-9b9316e9be11"
      },
      "source": [
        "#Import dataset\n",
        "path = \"drive/MyDrive/EE258 Project/Dataset_BUSI_with_GT\"\n",
        "dir_list = [os.path.join(path,i) for i in os.listdir(path)]\n",
        "size_dict = {}\n",
        "for i,value in enumerate(dir_list):\n",
        "    size_dict[os.listdir(path)[i]] = len(os.listdir(value))\n",
        "size_dict "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'benign': 891, 'malignant': 421, 'normal': 266}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khFNFZaTCI9L"
      },
      "source": [
        "import re\n",
        "def clean(name):\n",
        "    name = re.sub('[benign ().p]','',str(name))\n",
        "    return name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3o7CcsOHCI_T",
        "outputId": "c92e3e7e-a5ca-4cc1-f6c7-c1b7c4754190"
      },
      "source": [
        "df = pd.DataFrame(os.listdir(dir_list[0]))\n",
        "\n",
        "df = df[0].apply(clean)\n",
        "\n",
        "df = df[~df.str.contains('mask',regex =False)]\n",
        "\n",
        "df_list = list(df)\n",
        "type(df_list)\n",
        "df_list.sort()\n",
        "print(len(df_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKQZHNX4CJBv"
      },
      "source": [
        "#image size\n",
        "img_size = 128\n",
        "img_channel = 3\n",
        "#sets X as a blank matrix of zeros\n",
        "#y is the actual matrix of the images\n",
        "X_b , Xm_b , y_b = np.zeros((437,img_size,img_size,img_channel)) , np.zeros((437,img_size,img_size,img_channel)) , np.full(437,'benign') \n",
        "X_n , Xm_n , y_n = np.zeros((133,img_size,img_size,img_channel)) , np.zeros((133,img_size,img_size,img_channel)) , np.full(133,'normal') \n",
        "X_m , Xm_m , y_m = np.zeros((210,img_size,img_size,img_channel)) , np.zeros((210,img_size,img_size,img_channel)) , np.full(210,'malignant')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzO1K9qdCJEG",
        "outputId": "211a3f04-18f2-4c1b-c858-22ba8dded647"
      },
      "source": [
        "#this block pairs the maked with the ultrasound image\n",
        "img1_path = os.path.join(os.path.join(path,'benign'),os.listdir(os.path.join(path,'benign'))[1])\n",
        "\n",
        "pil_img = load_img(img1_path,color_mode = 'rgb',target_size=(img_size,img_size))\n",
        "img = img_to_array(pil_img)\n",
        "img_shape = img.shape\n",
        "print(img_shape)\n",
        "\n",
        "def img_num(filename):\n",
        "    \n",
        "    val = 0\n",
        "    #this loop looks for image numbers and matches Ultrasound image with masked image\n",
        "    for i in range(len(filename)) :\n",
        "        if filename[i] == '(' :\n",
        "            while True :\n",
        "                i += 1\n",
        "                if filename[i] == ')' :\n",
        "                    break\n",
        "                val = (val*10) + int(filename[i])\n",
        "            break\n",
        "    \n",
        "    return val\n",
        "#separates ultrasound and masked images\n",
        "for tumor_path in dir_list :\n",
        "    for image in os.listdir(tumor_path) :\n",
        "        p = os.path.join(tumor_path, image)\n",
        "        pil_img = load_img(p,color_mode = 'rgb',target_size=(img_size,img_size))         # read image as grayscale and resize it\n",
        "        \n",
        "        if image[-5] == ')' :                                   #if real image \n",
        "            #Ultrasound images\n",
        "            if image[0] == 'b' :\n",
        "                X_b[img_num(image)-1]+= img_to_array(pil_img)  # If image is real add it\n",
        "            if image[0] == 'n' :                               # to X as benign , normal\n",
        "                X_n[img_num(image)-1]+= img_to_array(pil_img)  # or malignant.\n",
        "            if image[0] == 'm' :\n",
        "                X_m[img_num(image)-1]+= img_to_array(pil_img)\n",
        "        else :                                                 #else masked image\n",
        "            #masked image\n",
        "            if image[0] == 'b' :\n",
        "                Xm_b[img_num(image)-1]+= img_to_array(pil_img)  # Similarly add the target\n",
        "            if image[0] == 'n' :                               # mask to y.\n",
        "                Xm_n[img_num(image)-1]+= img_to_array(pil_img)\n",
        "            if image[0] == 'm' :\n",
        "                Xm_m[img_num(image)-1]+= img_to_array(pil_img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 128, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cw6ECJTWn_j",
        "outputId": "9e067124-946e-42be-8fae-db5b2a4f3224"
      },
      "source": [
        "#combining sorted images into matricies\n",
        "X = np.concatenate((X_b, X_n, X_m), axis = 0) #combining real images into real image matrix {real_b, real_n, real_m}\n",
        "Xm = np.concatenate((Xm_b, Xm_n, Xm_m), axis = 0) #masked array\n",
        "\n",
        "#0 is black, 255 is white\n",
        "\n",
        "y = np.concatenate((y_b, y_n, y_m), axis = 0) #lables\n",
        "\n",
        "print(X.shape)  #Ultrasound image matrix\n",
        "print(Xm.shape) #masked image matrix\n",
        "print(y.shape)  #actual \n",
        "#look at max and min \n",
        "print(X.max())\n",
        "print(X.min())\n",
        "print(Xm.max())\n",
        "print(Xm.min())\n",
        "\n",
        "#normalize to max value\n",
        "X /= 255.0\n",
        "\n",
        "#normalize to max value\n",
        "Xm /= 510.0\n",
        "#combine Ulatrasound Image with Mask\n",
        "X_combined=X*Xm\n",
        "\n",
        "#look at max and min \n",
        "print(X.max())\n",
        "print(Xm.min())\n",
        "print(X_combined.max())\n",
        "print(X_combined.min())\n",
        "#look at type\n",
        "type(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(780, 128, 128, 3)\n",
            "(780, 128, 128, 3)\n",
            "(780,)\n",
            "(780, 128, 128, 3)\n",
            "255.0\n",
            "0.0\n",
            "510.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "0.5\n",
            "0.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "AQZOic0sCJI0",
        "outputId": "5636afa5-82ec-49fe-c587-8113a1cb7310"
      },
      "source": [
        "#Plot Bar Graph\n",
        "\n",
        "digit_train, counts_train = np.unique(y_m, return_counts = True)\n",
        "digit_train1, counts_train1 = np.unique(y_b, return_counts = True)\n",
        "digit_train2, counts_train2 = np.unique(y_n, return_counts = True)\n",
        "\n",
        "distribution_train = dict(zip(digit_train, counts_train))\n",
        "print(distribution_train)\n",
        "\n",
        "distribution_train1 = dict(zip(digit_train1, counts_train1))\n",
        "print(distribution_train1)\n",
        "\n",
        "distribution_train2 = dict(zip(digit_train2, counts_train2))\n",
        "print(distribution_train2)\n",
        "\n",
        "plt.bar(list(distribution_train.keys()),distribution_train.values(),width=0.6)\n",
        "plt.bar(list(distribution_train1.keys()),distribution_train1.values(),width=0.6)\n",
        "plt.bar(list(distribution_train2.keys()),distribution_train2.values(),width=0.6)\n",
        "plt.xlabel('Diagnosis of tumor')\n",
        "plt.ylabel('counts')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'malignant': 210}\n",
            "{'benign': 437}\n",
            "{'normal': 133}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDyeR9yQCJK9",
        "outputId": "1cc08c21-d20e-41d3-b289-2a8f208bebab"
      },
      "source": [
        "#Model Improvements LSTM\n",
        "#Test Train Split\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "encoder  = OneHotEncoder()\n",
        "# y = y.toarray()\n",
        "y=encoder.fit_transform(y.reshape(y.shape[0],1))\n",
        "\n",
        "# origonal ultrasound image \n",
        "#test train split is 3/20 (0.15)\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.15,shuffle=True,random_state=42)\n",
        "#validation data split is 1/10 (0.1) --> 0.15\n",
        "X_train,X_val,y_train,y_val = train_test_split(X_train,y_train,test_size=0.1,random_state=42,stratify = y_train.toarray())\n",
        "\n",
        "#combined images\n",
        "#test train split is 3/20 (0.15)\n",
        "X_train_c,X_test_c,y_train_c,y_test_c = train_test_split(X_combined,y,test_size = 0.15,shuffle=True,random_state=42)\n",
        "#combined validation split\n",
        "X_train_c,X_val_c,y_train_c,y_val_c = train_test_split(X_train_c,y_train_c,test_size=0.1,random_state=42,stratify = y_train_c.toarray())\n",
        "\n",
        "#Masked image\n",
        "#test train split is 3/20 (0.15) \n",
        "Xm_train,Xm_test,ym_train,ym_test = train_test_split(Xm,y,test_size = 0.15,shuffle=True,random_state=42,stratify=y.toarray())\n",
        "#validation data split is 1/10 (0.1)\n",
        "Xm_train,Xm_val,ym_train,ym_val = train_test_split(Xm_train,ym_train,test_size=0.1,random_state=42,stratify = ym_train.toarray())\n",
        "\n",
        "class_list = encoder.categories_\n",
        "print(X_train.shape,X_test.shape)\n",
        "print(y_train.shape,y_test.shape)\n",
        "print(Xm_train.shape,Xm_test.shape)\n",
        "print(ym_train.shape,ym_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(596, 128, 128, 3) (117, 128, 128, 3)\n",
            "(596, 3) (117, 3)\n",
            "(596, 128, 128, 3) (117, 128, 128, 3)\n",
            "(596, 3) (117, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0m8dZY5CJNK"
      },
      "source": [
        "base_model = tf.keras.applications.InceptionV3(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=img_shape,\n",
        "    pooling=None\n",
        ")\n",
        "\n",
        "X_feat_out = base_model.output\n",
        "X_feat_flatten = Flatten()(X_feat_out)\n",
        "\n",
        "X_feat_model = Model(inputs = base_model.input,outputs = X_feat_flatten)\n",
        "X_feat_train = X_feat_model.predict(X_train)\n",
        "X_feat_val = X_feat_model.predict(X_val)\n",
        "X_feat_test = X_feat_model.predict(X_test)\n",
        "\n",
        "Xm_feat_train = X_feat_model.predict(Xm_train)\n",
        "Xm_feat_val = X_feat_model.predict(Xm_val)\n",
        "Xm_feat_test = X_feat_model.predict(Xm_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kf9RsjBtCJPg"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from tensorflow.keras.layers import LSTM,Bidirectional,Reshape\n",
        "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score,roc_auc_score,cohen_kappa_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9BHcrCbCJRz"
      },
      "source": [
        "df = pd.DataFrame(columns = ['classifier',\"train_accuracy\",'val_accuracy',\"test_accuracy\",\"f1_measure\",\"kappa_score\",\"recall\",\"Precision\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9I_c5EACJUL"
      },
      "source": [
        "def eval(classifier_name,y_train,y_train_pred,y_val,y_val_pred,y_true,y_pred):\n",
        "    y_train = np.argmax(y_train,axis=1)\n",
        "\n",
        "    y_val = np.argmax(y_val,axis=1)\n",
        "\n",
        "    y_true = np.argmax(y_true,axis=1)\n",
        "\n",
        "    train_accuracy = round(accuracy_score(y_train,y_train_pred),4)\n",
        "    val_accuracy = round(accuracy_score(y_val,y_val_pred),4)\n",
        "    test_accuracy = round(accuracy_score(y_true,y_pred),4)\n",
        "    f1_measure = round(f1_score(y_true,y_pred,average='weighted'),4)\n",
        "    kappa_score = round(cohen_kappa_score(y_true,y_pred),4)\n",
        "    recall = round(recall_score(y_true,y_pred,average='weighted'),4)\n",
        "    precision = round(precision_score(y_true,y_pred,average='weighted'),4)\n",
        "    \n",
        "    score = {\"classifier\":classifier_name,\"train_accuracy\":train_accuracy , \"val_accuracy\":val_accuracy,\"test_accuracy\":test_accuracy,\"f1_measure\":f1_measure,\"kappa_score\":kappa_score,\"recall\":recall,\"precision\":precision}\n",
        "\n",
        "    df.loc[len(df.index)] = score.values()\n",
        "    for e,a in score.items():\n",
        "        print(e,a)\n",
        "    print(\"--\"*20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IxVaeXyCJWO"
      },
      "source": [
        "def classifier_eval(classifier,classifier_name,X_train,y_train,X_val,y_val,X_test,y_test):\n",
        "    \n",
        "    classifier.fit(X_train,np.argmax(y_train,axis=1))\n",
        "    \n",
        "    y_train_pred = classifier.predict(X_train)\n",
        "    y_val_pred = classifier.predict(X_val)\n",
        "    y_test_pred = classifier.predict(X_test)\n",
        "    \n",
        "    eval(classifier_name,y_train,y_train_pred,y_val,y_val_pred,y_test,y_test_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGWatCopEhHq"
      },
      "source": [
        "for l in base_model.layers:\n",
        "    l.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jt3tFiXtEhKP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cc9c626-dbeb-4de3-9cb9-f7b9afaa4a39"
      },
      "source": [
        "#LSTM Model\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(base_model)\n",
        "lstm_model.add(Reshape((base_model.output.shape[1]*base_model.output.shape[2],base_model.output.shape[3])))\n",
        "lstm_model.add(LSTM(128, dropout=0.5,recurrent_dropout=0.5))\n",
        "lstm_model.add(Dense(3,activation='softmax'))\n",
        "\n",
        "lstm_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IN3mclREhPx"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', patience=4,restore_best_weights=True, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMOx4LPLE-QG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "808b4e73-3e29-4f8f-82db-b6a3fcc13bf1"
      },
      "source": [
        "#Training the LSTM model\n",
        "history = lstm_model.fit(X_train_c,y_train_c.toarray(),epochs = 20,validation_data = (X_val_c,y_val_c.toarray()),callbacks = [es])\n",
        "lstm_train_predict = np.argmax(lstm_model.predict(X_train_c),axis=1)\n",
        "lstm_val_predict = np.argmax(lstm_model.predict(X_val_c),axis=1)\n",
        "lstm_test_predict = np.argmax(lstm_model.predict(X_test_c),axis=1)\n",
        "eval(\"LSTM\",y_train_c,lstm_train_predict,y_val_c,lstm_val_predict,y_test_c,lstm_test_predict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "19/19 [==============================] - 13s 234ms/step - loss: 0.3203 - acc: 0.8607 - val_loss: 0.1786 - val_acc: 0.9403\n",
            "Epoch 2/20\n",
            "19/19 [==============================] - 2s 117ms/step - loss: 0.1314 - acc: 0.9497 - val_loss: 0.1417 - val_acc: 0.9552\n",
            "Epoch 3/20\n",
            "19/19 [==============================] - 2s 105ms/step - loss: 0.0955 - acc: 0.9715 - val_loss: 0.1517 - val_acc: 0.9552\n",
            "Epoch 4/20\n",
            "19/19 [==============================] - 2s 107ms/step - loss: 0.0764 - acc: 0.9799 - val_loss: 0.1035 - val_acc: 0.9851\n",
            "Epoch 5/20\n",
            "19/19 [==============================] - 2s 97ms/step - loss: 0.0545 - acc: 0.9866 - val_loss: 0.1152 - val_acc: 0.9851\n",
            "Epoch 6/20\n",
            "19/19 [==============================] - 2s 98ms/step - loss: 0.0415 - acc: 0.9832 - val_loss: 0.1244 - val_acc: 0.9552\n",
            "Epoch 7/20\n",
            "19/19 [==============================] - 2s 97ms/step - loss: 0.0337 - acc: 0.9933 - val_loss: 0.1231 - val_acc: 0.9552\n",
            "Epoch 8/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0200 - acc: 0.9950Restoring model weights from the end of the best epoch: 4.\n",
            "19/19 [==============================] - 2s 118ms/step - loss: 0.0200 - acc: 0.9950 - val_loss: 0.1291 - val_acc: 0.9552\n",
            "Epoch 00008: early stopping\n",
            "classifier LSTM\n",
            "train_accuracy 0.9916\n",
            "val_accuracy 0.9851\n",
            "test_accuracy 0.9658\n",
            "f1_measure 0.9654\n",
            "kappa_score 0.9442\n",
            "recall 0.9658\n",
            "precision 0.968\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRPfVaWKE-SW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13640343-6ab0-4cc5-ac97-047446bfafb0"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "rounded_labels=np.argmax(y_test_c, axis=1)\n",
        "rounded_labels[1]\n",
        "print('Confusion Matrix of LSTM Model')\n",
        "print(confusion_matrix(lstm_test_predict, rounded_labels))\n",
        "print('   b, m, n')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix of LSTM Model\n",
            "[[58  4  0]\n",
            " [ 0 33  0]\n",
            " [ 0  0 22]]\n",
            "   b, m, n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bldtKxpN9Mnk"
      },
      "source": [
        "***Now Try a Bi-Directional LSTM MODEL***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKT-0tQi3N1F",
        "outputId": "dea49574-4c06-4cf2-e1dc-a10760cd0c98"
      },
      "source": [
        "#Bi-Dirrectional LSTM Model \n",
        "bidir_model = Sequential()\n",
        "bidir_model.add(base_model)\n",
        "bidir_model.add(Reshape((base_model.output.shape[1]*base_model.output.shape[2],base_model.output.shape[3])))\n",
        "bidir_model.add(Bidirectional(LSTM(128, dropout=0.5,recurrent_dropout=0.5)))\n",
        "bidir_model.add(Dense(3,activation='softmax'))\n",
        "\n",
        "bidir_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRJoUf_SE-Uy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b147c33-9909-4677-8773-088097343c84"
      },
      "source": [
        "#Train Bi-Directional LSTM Model\n",
        "history = bidir_model.fit(X_train_c,y_train_c.toarray(),epochs = 20,validation_data = (X_val,y_val_c.toarray()),callbacks = [es])\n",
        "bidir_train_predict = np.argmax(bidir_model.predict(X_train_c),axis=1)\n",
        "bidir_val_predict = np.argmax(bidir_model.predict(X_val_c),axis=1)\n",
        "bidir_test_predict = np.argmax(bidir_model.predict(X_test_c),axis=1)\n",
        "eval(\"Bi-LSTM\",y_train_c,bidir_train_predict,y_val_c,bidir_val_predict,y_test_c,bidir_test_predict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "19/19 [==============================] - 16s 258ms/step - loss: 0.3307 - acc: 0.8674 - val_loss: 1.5337 - val_acc: 0.6269\n",
            "Epoch 2/20\n",
            "19/19 [==============================] - 2s 118ms/step - loss: 0.1318 - acc: 0.9513 - val_loss: 1.8783 - val_acc: 0.5672\n",
            "Epoch 3/20\n",
            "19/19 [==============================] - 2s 118ms/step - loss: 0.0863 - acc: 0.9715 - val_loss: 2.6180 - val_acc: 0.5672\n",
            "Epoch 4/20\n",
            "19/19 [==============================] - 2s 118ms/step - loss: 0.0743 - acc: 0.9765 - val_loss: 2.0536 - val_acc: 0.5970\n",
            "Epoch 5/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0474 - acc: 0.9866Restoring model weights from the end of the best epoch: 1.\n",
            "19/19 [==============================] - 3s 136ms/step - loss: 0.0474 - acc: 0.9866 - val_loss: 2.1865 - val_acc: 0.5970\n",
            "Epoch 00005: early stopping\n",
            "classifier Bi-LSTM\n",
            "train_accuracy 0.9564\n",
            "val_accuracy 0.9552\n",
            "test_accuracy 0.9573\n",
            "f1_measure 0.9566\n",
            "kappa_score 0.9301\n",
            "recall 0.9573\n",
            "precision 0.9607\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooGRSWvSE-XK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "454c612f-7e7d-4490-9cbf-61655f86abf9"
      },
      "source": [
        "#Confusion Matrix \n",
        "#of Bidirectional LSTM Model\n",
        "\n",
        "print('Confusion Matrix of Bi-Directional Model')\n",
        "print(confusion_matrix(bidir_test_predict, rounded_labels))\n",
        "print('   b, m, n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix of Bi-Directional Model\n",
            "[[58  5  0]\n",
            " [ 0 32  0]\n",
            " [ 0  0 22]]\n",
            "   b, m, n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sGMSCFlE-Zf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwdDx7-bE-bq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwBVwWhFE-dV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}